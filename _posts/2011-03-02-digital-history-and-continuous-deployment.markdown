--- 
layout: post
title: Digital History and Continuous Deployment
date: 2011-03-02 07:45:53 -06:00
tags:
- digital-humanities
- publishing
category: research
---
The other night on <a href="http://www.reddit.com/r/programming/">Proggit</a> I came across a <a href="http://fragile.org.uk/2011/02/in-praise-of-continuous-deployment/">blog post</a> praising continuous deployment. Continuous deployment is the process of code written for applications are immediately deployed which <a href="http://radar.oreilly.com/2009/03/continuous-deployment-5-eas.html">lowers cycle time and opens up individual initiative</a>.  As I was reading the post and doing a bit of my own Googling I began to wonder if continuous deployment worked as a metaphor for digital scholarship. These are my quick thoughts.

I don't mean continuous deployment in the sense that developers mean continuous deployment. After all, digital history projects are not necessarily in the business of testing and debugging for consumers.[1. Though there is certainly a place for that in terms of user interfaces and visualizations.] Rather, I mean continuous deployment in digital history to be the continual refinement of narrative and analysis, the ongoing growth of digital archives, and the implementation of current and future visualizations.

At conferences and in discussions with people unfamiliar with digital history, I often talk about the iterative process of digital history -- that the finality of a journal article, dissertation, or book could seemingly never exist for digital projects given the nearly unlimited space for data, information, and space that our modern servers and hard drives provide (unlike the analog limitations of ink, paper, and costs). More than one conversation has wandered into whether this sort of scholarship was good for history. After all, if the content of a digital project is continually changing, can a project be reliable for its posterity? The skeptics raise an important point. Indeed, if continual research leads a scholar to draw new or different conclusions than originally posited on a project, should there be some way to archive &quot;old&quot; narratives and analysis for posterity's sake? I'm sympathetic to this view, especially since one of our goals with digital scholarship should be citable material. We need some sort of stability, though I don't know exactly what version-controlled digital scholarship looks like yet.

However, I think there is a larger point to be made about continuous deployment in DH. The iterative process allows us to react to new data or interpretations, easily update material, and also unlocks data and knowledge for broad audiences.

<h4>Scholarship More Agile</h4>
Programmers talk of their <a href="http://en.wikipedia.org/wiki/Agile_software_development#Agile_Manifesto">projects being agile</a>, meaning that software can adapt quickly to changes or add functionality with little risk. The same could be said for digital history. There is a tremendous amount of risk in publishing a book or journal article -- the sale and marketing of the product, the costs of physical media, the time of editing and revision. In digital history, these items can simultaneously occur or could be eliminated entirely. The nearly limitless space that modern hard drives allow us means we can create digital projects that encompass a very wide array of subjects and material without the physical limitations of ink and paper. Digital publication doesn't require a reprinting or new edition: we can adapt to changes very quickly (new scholarly interpretations, new visualizations, etc.) or expand digital archives with relative ease.

<h4>Easy Revision and Updating</h4>
Agile development allows for ease in revising and updating material in digital projects. Revising narrative or archive items is a simple matter compared to the amount of work and investment it takes to update print publications. Changes to my own projects involve no more than connecting to my server or editing local files for upload. In a matter of moments, my changes are &quot;live&quot; for users to begin using or interpreting.

<h4>No Gatekeepers</h4>
Digital history <a href="http://www.jasonheppler.org/2010/10/08/open-access-scholarship-and-computers-in-the-humanities/">should be open</a>. While I respect and am thankful for the material that services like JSTOR and ProQuest offer, unfortunately this material is locked behind costly gates. The sum of the world's knowledge should be open for broad consumption. Perhaps the Google Books model is one way journal publishers can begin thinking about ways of sharing the contents of their journals. 
